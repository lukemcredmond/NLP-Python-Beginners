{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chapter 13\n",
    "\n",
    "Word Representations\n",
    "\n",
    "one hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AGF'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "L = list(nlp.vocab.strings)\n",
    "numWords = len(L)\n",
    "print(numWords)\n",
    "\n",
    "W2I = dict(zip(L,np.arange(numWords)))\n",
    "I2W = dict(zip(np.arange(numWords),L))\n",
    "\n",
    "\n",
    "\n",
    "W2I['game']\n",
    "I2W[83814]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oneHotVector(word,W2I,numWords):\n",
    "    v = np.zeros(numWords)\n",
    "    v[W2I[word]] = 1\n",
    "    return v\n",
    "\n",
    "v = oneHotVector('game',W2I,numWords)\n",
    "\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How',\n",
       " 'are',\n",
       " 'you',\n",
       " 'today',\n",
       " '.',\n",
       " 'I',\n",
       " 'know',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " 'time',\n",
       " 'how',\n",
       " 'you',\n",
       " 'feel',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape\n",
    "\n",
    "v[W2I['game']]\n",
    "\n",
    "doc = 'How are you today. I know most of the time how you feel.'\n",
    "tokens = [token.text for token in nlp(doc)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = np.zeros(numWords)\n",
    "for token in tokens:\n",
    "    v += oneHotVector(token,W2I,numWords)\n",
    "\n",
    "v\n",
    "\n",
    "v[W2I['.']]\n",
    "\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups as getData\n",
    "corpus = getData(subset='train',remove=('headers','footers','qoutes'))\n",
    "docs = corpus.data\n",
    "len(docs)\n",
    "\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.zeros(numWords)\n",
    "\n",
    "for term in L:\n",
    "    dft = 0\n",
    "    for doc in docs[:100]:\n",
    "        if term in doc:\n",
    "            dft += 1\n",
    "    df[W2I[term]] = dft\n",
    "\n",
    "df\n",
    "N = 100\n",
    "Idf = np.log10(N/(df+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'How are you today. I know most of the time how you feel.'\n",
    "v = np.zeros(numWords)\n",
    "for token in nlp(doc):\n",
    "    v += oneHotVector(token.text,W2I,numWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = np.log10(v+1)\n",
    "tfidf = tf*Idf\n",
    "tfidf\n",
    "\n",
    "\n",
    "np.sum(tfidf != 0)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
