{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chapter 23\n",
    "\n",
    "Vocabulary Implementation\n",
    "\n",
    "determine negative/positive feed back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "vocab = {}\n",
    "df = pd.read_csv(r'../data/Womens Clothing E-Commerce Reviews.csv')\n",
    "\n",
    "\n",
    "def initializeVocabulary():\n",
    "    unkToken = '<UNK>'\n",
    "    vocab['t_2_i'] = {}\n",
    "    vocab['i_2_t'] = {}\n",
    "    idx = addToken(unkToken)\n",
    "    vocab['addUnk'] = True\n",
    "    vocab['unkToken'] = unkToken\n",
    "    vocab['unkTokenIdx'] = idx\n",
    "\n",
    "def addToken(token):\n",
    "    if token in vocab['t_2_i']:\n",
    "        idx = vocab['t_2_i'][token]\n",
    "    else:\n",
    "        idx = len(vocab['t_2_i'])\n",
    "        vocab['t_2_i'][token] = idx\n",
    "        vocab['i_2_t'][idx] = token\n",
    "    return idx\n",
    "\n",
    "def addManyTokens(tokens):\n",
    "    idxes = [addToken(token) for token in tokens]\n",
    "    return idxes\n",
    "\n",
    "def lookUpToken(token):\n",
    "    if vocab['unkTokenIdx'] >= 0:\n",
    "        return vocab['t_2_i'].get(token,vocab['unkTokenIdx'])\n",
    "    else:\n",
    "        return vocab['t_2_i'][token]\n",
    "\n",
    "def lookUpIndex(idx):\n",
    "    if idx not in vocab['i_2_t']:\n",
    "        raise KeyError(\"the index (%d) is not there\" % idx)\n",
    "    return vocab['i_2_t'][idx]\n",
    "\n",
    "def vocabularyFromDataFrame(df,cutoff=25):\n",
    "    initializeVocabulary()\n",
    "    wordCounts = Counter()\n",
    "    for r in df[\"Review Text\"].fillna('').apply(str):\n",
    "        if(r):\n",
    "            for word in r.split(\" \"):\n",
    "                if word not in string.punctuation:\n",
    "                    wordCounts[word] += 1\n",
    "    for word,count in wordCounts.items():\n",
    "        if count > cutoff:\n",
    "            addToken(word)\n",
    "\n",
    "def vectorize(review):\n",
    "    isFirst = True\n",
    "\n",
    "    for token in str(review).split(\" \"):\n",
    "        if token not in string.punctuation:\n",
    "            oneHot = np.zeros((len(vocab['t_2_i']),1))\n",
    "            oneHot[lookUpToken(token)] = 1\n",
    "            if isFirst:\n",
    "                xF = oneHot\n",
    "                isFirst = False\n",
    "            else:\n",
    "                xF = np.hstack((xF,oneHot))\n",
    "    return xF\n",
    "\n",
    "#vocabularyFromDataFrame(df,cutoff=25)\n",
    "\n",
    "#lookUpToken('this')\n",
    "\n",
    "#lookUpIndex(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#xF = vectorize(df['Review Text'][1])\n",
    "\n",
    "smallDf_pos = df[df['Rating'] >= 3].iloc[:300]#get 5 positive rows from the data set df\n",
    "smallDf_neg = df[df['Rating'] < 3].iloc[:300]#get 5 negative rows from the data set df\n",
    "df_small = pd.concat([smallDf_pos,smallDf_neg],axis=0)\n",
    "\n",
    "#df_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch=0: 4.155557\n",
      "Loss after epoch=1: 4.105794\n",
      "Loss after epoch=2: 4.056082\n",
      "Loss after epoch=3: 4.006422\n",
      "Loss after epoch=4: 3.956820\n",
      "Loss after epoch=5: 3.907278\n",
      "Loss after epoch=6: 3.857801\n",
      "Loss after epoch=7: 3.808393\n",
      "Loss after epoch=8: 3.759058\n",
      "Loss after epoch=9: 3.709801\n",
      "Loss after epoch=10: 3.660627\n",
      "Loss after epoch=11: 3.611541\n",
      "Loss after epoch=12: 3.562549\n",
      "Loss after epoch=13: 3.513657\n",
      "Loss after epoch=14: 3.464872\n",
      "Loss after epoch=15: 3.416201\n",
      "Loss after epoch=16: 3.367650\n",
      "Loss after epoch=17: 3.319227\n",
      "Loss after epoch=18: 3.270942\n",
      "Loss after epoch=19: 3.222801\n",
      "Loss after epoch=20: 3.174815\n",
      "Loss after epoch=21: 3.126994\n",
      "Loss after epoch=22: 3.079346\n",
      "Loss after epoch=23: 3.031885\n",
      "Loss after epoch=24: 2.984620\n",
      "Loss after epoch=25: 2.937564\n",
      "Loss after epoch=26: 2.890731\n",
      "Loss after epoch=27: 2.844132\n",
      "Loss after epoch=28: 2.797783\n",
      "Loss after epoch=29: 2.751697\n",
      "Loss after epoch=30: 2.705892\n",
      "Loss after epoch=31: 2.660382\n",
      "Loss after epoch=32: 2.615185\n",
      "Loss after epoch=33: 2.570319\n",
      "Loss after epoch=34: 2.525801\n",
      "Loss after epoch=35: 2.481651\n",
      "Loss after epoch=36: 2.437889\n",
      "Loss after epoch=37: 2.394535\n",
      "Loss after epoch=38: 2.351610\n",
      "Loss after epoch=39: 2.309136\n",
      "Loss after epoch=40: 2.267134\n",
      "Loss after epoch=41: 2.225628\n",
      "Loss after epoch=42: 2.184641\n",
      "Loss after epoch=43: 2.144195\n",
      "Loss after epoch=44: 2.104315\n",
      "Loss after epoch=45: 2.065025\n",
      "Loss after epoch=46: 2.026347\n",
      "Loss after epoch=47: 1.988306\n",
      "Loss after epoch=48: 1.950926\n",
      "Loss after epoch=49: 1.914229\n"
     ]
    }
   ],
   "source": [
    "vocabularyFromDataFrame(df_small,cutoff=10)\n",
    "\n",
    "numFeatures = len(vocab['t_2_i'])\n",
    "hiddenUnits = 10\n",
    "h0 = torch.tensor(np.zeros((hiddenUnits,1)))\n",
    "Wx = torch.tensor(np.random.uniform(0,1,(hiddenUnits,numFeatures)),requires_grad=True)\n",
    "Wh = torch.tensor(np.random.uniform(0,1,(hiddenUnits,hiddenUnits)),requires_grad=True)\n",
    "Wy = torch.tensor(np.random.uniform(0,1,(1,hiddenUnits)),requires_grad=True)# only \n",
    "\n",
    "def stepForward(xt,Wx,Wh,Wy,prevMemory):\n",
    "    x_frd = torch.matmul(Wx,torch.from_numpy(xt[:,np.newaxis]))\n",
    "    h_frd = torch.matmul(Wh,prevMemory)\n",
    "    ht = torch.tanh(x_frd+h_frd)\n",
    "    yt_hat = torch.sigmoid(torch.matmul(Wy,ht))#sigmoid as we have only one output\n",
    "    return ht,yt_hat\n",
    "\n",
    "def fullForwardRNN(X,Wx,Wh,Wy,prevMemory):\n",
    "    y_hat = 0\n",
    "    for t in range(X.shape[1]):\n",
    "        ht,yt_hat = stepForward(X[:,t],Wx,Wh,Wy,prevMemory)\n",
    "        prevMemory = ht\n",
    "        y_hat = yt_hat\n",
    "    return y_hat  \n",
    "\n",
    "def computeLoss(y,y_hat):\n",
    "    loss = 0\n",
    "    for yi,yi_hat in zip(y,y_hat):\n",
    "        if yi == 1:\n",
    "            loss += -torch.log2(yi_hat)\n",
    "        else:\n",
    "            loss += -torch.log2(1-yi_hat)\n",
    "    return loss/len(y)\n",
    "\n",
    "def updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr):\n",
    "    with torch.no_grad():\n",
    "        Wx -= lr*dWx\n",
    "        Wh -= lr*dWh\n",
    "        Wy -= lr*dWy\n",
    "    return Wx,Wh,Wy\n",
    "\n",
    "def trainRNN(train_df,Wx,Wh,Wy,prevMemory,lr,nepoch):\n",
    "    losses = []\n",
    "    for epoch in range(nepoch):\n",
    "        y,y_hat = [],[]\n",
    "        for rv,rt in zip(train_df['Review Text'],train_df['Rating']):\n",
    "            X = vectorize(rv)\n",
    "            yi_hat = fullForwardRNN(X,Wx,Wh,Wy,prevMemory)\n",
    "            yi = 0\n",
    "            if rt >= 3:\n",
    "                yi = 1\n",
    "            y.append(yi)\n",
    "            y_hat.append(yi_hat)\n",
    "            \n",
    "        loss = computeLoss(y,y_hat)\n",
    "        loss.backward()\n",
    "        losses.append(loss)\n",
    "        print(\"Loss after epoch=%d: %f\" %(epoch,loss))\n",
    "        sys.stdout.flush()\n",
    "        dWx = Wx.grad.data\n",
    "        dWh = Wh.grad.data\n",
    "        dWy = Wy.grad.data\n",
    "        Wx,Wh,Wy = updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr)\n",
    "        Wx.grad.data.zero_()\n",
    "        Wh.grad.data.zero_()\n",
    "        Wy.grad.data.zero_()\n",
    "    return Wx,Wh,Wy,losses\n",
    "\n",
    "Wx,Wh,Wy,losses = trainRNN(df_small,Wx,Wh,Wy,h0,0.01,50)\n",
    "\n",
    "#r = df_small['Review Text'].iloc[6]\n",
    "#y = df_small['Rating'].iloc[6]\n",
    "\n",
    "#X = vectorize(r)\n",
    "\n",
    "#y_hat = fullForwardRNN(X,Wx,Wh,Wy,h0)\n",
    "\n",
    "#print(y_hat)\n",
    "\n",
    "#print(y)\n",
    "\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7095]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X1 = vectorize(\"great\")\n",
    "\n",
    "y1_hat = fullForwardRNN(X1,Wx,Wh,Wy,h0)\n",
    "\n",
    "print(y1_hat)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
