{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14\n",
    "\n",
    "Word Representations/word embeddings\n",
    "\n",
    "word cooccurrence matrix/\n",
    "term-term Matrix/\n",
    "Term-Context matrix\n",
    "\n",
    "\n",
    "Window-size/context-size\n",
    "\n",
    "example window-size 2\n",
    "check words 2 left and 2 right\n",
    "XXX XXX Cherry XXX XXX\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358064\n",
      "59077\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "doc = open('../data/azureDevOps.txt',encoding=\"utf8\").read().lower()\n",
    "\n",
    "doclen = len(doc)\n",
    "\n",
    "corpus_list = re.split('\\W+',doc)\n",
    "\n",
    "corpuslen = len(corpus_list)\n",
    "\n",
    "print(doclen)\n",
    "print(corpuslen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34004"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutOffValue = 100\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for token in corpus_list:\n",
    "    frequency[token] += 1\n",
    "processedCorpus_list = [token for token in corpus_list \n",
    "                        if frequency[token] >= cutOffValue]\n",
    "\n",
    "len(processedCorpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allWords = np.array(list(frequency.keys()))\n",
    "allCounts = np.array(list(frequency.values()))\n",
    "\n",
    "vocab = allWords[allCounts >= cutOffValue]\n",
    "wordCounts = allCounts[allCounts >= cutOffValue]\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 108)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def computeWordContextMatrix(corpus_list,vocab=None,windowSize=2):\n",
    "    if vocab is None:\n",
    "        vocab = sorted(list(set(cospus_list)))\n",
    "    numWords = len(vocab)\n",
    "    M = np.zeros((numWords,numWords))\n",
    "    #M = lil_matrix((numWords,numWords))#use for large matrix put takes longer\n",
    "    W2I = dict(zip(vocab,np.arange(numWords)))\n",
    "    I2W = dict(zip(np.arange(numWords),vocab))\n",
    "    doc = corpus_list\n",
    "    curIdx = 0\n",
    "    docLen = len(doc)\n",
    "    while curIdx < docLen:\n",
    "        left = max(curIdx-windowSize,0)\n",
    "        right = min(curIdx+windowSize+1,docLen)\n",
    "        wordsInContext = doc[left:curIdx] + doc[curIdx+1:right]\n",
    "        currentWord = doc[curIdx]\n",
    "        currentWordIdx = W2I[currentWord]\n",
    "        for word in wordsInContext:\n",
    "            contextWordIdx = W2I[word]\n",
    "            M[currentWordIdx,contextWordIdx] += 1\n",
    "        curIdx += 1\n",
    "    return M,W2I,I2W\n",
    "\n",
    "M,W2I,I2W = computeWordContextMatrix(processedCorpus_list,vocab)\n",
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['azure' 'devops' 'with' 'and' 'your' 'all' 'of' 'this' 'be' 'in' 'a' 'or'\n",
      " 'by' 'the' 'to' 'is' 's' 'will' 'for' 'have' 'use' 'development'\n",
      " 'project' '1' '3' 'com' 'our' 'as' 'you' 'from' '4' 'that' 'can' 'at'\n",
      " 'are' 'on' 'also' 'up' 'microsoft' 'an' 'it' 'now' 'work' 'using'\n",
      " 'application' '6' 'new' 'if' 'we' 'section' '2' 'create' '5' 'ci' 'cd'\n",
      " 'control' 'code' 'boards' 'pipelines' 'test' 'artifacts' 'creating'\n",
      " 'organization' 'items' 'source' 'github' 'repository' 'pull' 'request'\n",
      " 'branch' 'visual' 'studio' 'release' 'build' 'agents' 'hosted' 'when'\n",
      " 'agent' 'pipeline' 'stage' 'container' 'testing' 'setting' 'set'\n",
      " 'package' 'deployment' 'based' 'service' 'chapter' 'how' 'add' 'need'\n",
      " 'following' 'https' 'next' 'used' 'here' 'run' 'name' 'see' 'select'\n",
      " 'then' 'different' 'figure' 'll' 'created' 'task' 'click']\n"
     ]
    }
   ],
   "source": [
    "len(vocab)\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 azure\n"
     ]
    }
   ],
   "source": [
    "word = 'azure'\n",
    "print(W2I[word],I2W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164. 772. 342. 202. 128.   7.  56.  26.  16. 257.  82.  30.  30. 250.\n",
      " 208.  52.  20.  17. 106.  15.  31.  11.  46.  44.  18. 102.  10.  73.\n",
      "  89.  45.  38.  26.  49.  14.  22.  52.   4.  42.  88.  88.  13.  12.\n",
      "  21.  64.  17.  27.   5.   6.  33.   9.  32.  23.  20.  19.  50.  56.\n",
      "  19. 124. 251.  76.  49.  51.  42.  11.   5.  69.  19.  10.   5.   7.\n",
      "   2.   9.  10.  14.  39.  22.  10. 121. 167.   6.  39.  10.  33.  15.\n",
      "   2.  20.   8.  54.  36.   8.   3.   6.   8.  44.   5.  13.   5.  10.\n",
      "   5.   5.  29.   4.  12.  61.   5.   6.  15.  19.]\n"
     ]
    }
   ],
   "source": [
    "v = M[W2I['azure'],:]\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 1.77202695, 1.24628025, 0.        , 0.33224931,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.30914361,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.50177976, 0.        ,\n",
       "       1.52111802, 0.        , 0.15002775, 0.        , 0.        ,\n",
       "       0.32421406, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.36510865, 1.07644534, 0.63981364,\n",
       "       0.        , 0.        , 0.        , 0.24493384, 0.        ,\n",
       "       0.372801  , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.10473576, 0.        , 0.09087872, 0.        , 0.7640434 ,\n",
       "       1.1967255 , 0.        , 1.73924145, 1.70982845, 0.32421406,\n",
       "       0.96878443, 0.3338249 , 0.90904343, 0.        , 0.        ,\n",
       "       0.39658333, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.52280229,\n",
       "       0.        , 0.        , 0.74747414, 0.3605763 , 0.        ,\n",
       "       0.75870809, 0.        , 0.47081754, 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.17030819, 0.42125338, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.76666292, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pmi(M, positive=True):\n",
    "    col_totals = np.sum(M,axis=0)\n",
    "    total = col_totals.sum()\n",
    "    row_totals = np.sum(M,axis=1)\n",
    "    expected = np.outer(row_totals, col_totals) / total\n",
    "    M = M / expected    \n",
    "    with np.errstate(divide='ignore'):\n",
    "        M = np.log(M)\n",
    "    M[np.isinf(M)] = 0.0  \n",
    "    if positive:\n",
    "        M[M < 0] = 0.0\n",
    "    return M\n",
    "\n",
    "M = pmi(M)\n",
    "M[W2I['azure'],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.94901798, -1.59300668,  0.71913953,  1.12980366,  1.59773673,\n",
       "        0.38685175,  1.28525832,  0.62673846,  0.18142335,  0.30662337,\n",
       "       -0.1308667 , -0.36504702,  0.4821801 , -0.09906275,  0.13812073,\n",
       "       -0.10821644,  0.28443539, -0.43743388,  0.30639659, -0.60988739,\n",
       "       -0.41023503,  0.19680526, -0.14679521,  0.81943244, -1.11180521,\n",
       "       -0.3513152 , -1.12093386,  0.10924543, -0.14510302,  0.88124274,\n",
       "        0.1707201 ,  0.41344565,  0.39674479, -0.09485438,  0.30663128,\n",
       "       -0.87749262, -0.16830552, -0.38545493, -0.23450951,  0.8415997 ,\n",
       "        0.32758856,  0.48751807, -0.49156696,  0.11984287, -0.30241775,\n",
       "        0.13327269, -0.54191605, -0.38719888, -0.31506158, -0.24696457,\n",
       "        0.19810125,  0.17332525,  0.30934387, -0.0890748 ,  0.14468264,\n",
       "        0.07520589, -0.32599125,  0.56718235,  0.22568295,  0.18819536,\n",
       "        0.04231654, -0.47154537, -0.0146015 , -0.3009912 ,  0.02071921,\n",
       "        0.01962504,  0.1051733 , -0.2679721 ,  0.17405856, -0.00565878,\n",
       "        0.09445263, -0.01183487,  0.36215614,  0.07425195, -0.00567387,\n",
       "       -0.05218933,  0.15156068,  0.23513657, -0.04531124, -0.13407563,\n",
       "        0.06963306, -0.06709613,  0.12337922, -0.10965512,  0.02267817,\n",
       "        0.14447222,  0.15036983, -0.02091335,  0.05320235,  0.06041125,\n",
       "       -0.00916345,  0.10507436, -0.06471965, -0.079984  , -0.09699943,\n",
       "        0.09240232, -0.08801317, -0.05569571, -0.02195575,  0.04699261])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD,PCA,IncrementalPCA\n",
    "transformer = TruncatedSVD(n_components=100)\n",
    "M_reduced = transformer.fit_transform(M)\n",
    "M_reduced.shape\n",
    "M.shape\n",
    "M_reduced[W2I['azure'],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNorms(E):\n",
    "    if E.ndim == 1:\n",
    "        E = E[np.newaxis,:]\n",
    "    nrms = np.sum(E**2,axis=1)**0.5\n",
    "    return nrms\n",
    "\n",
    "def normalize(E):\n",
    "    if E.ndim == 1:\n",
    "        E = E[np.newaxis,:]\n",
    "    nrms = getNorms(E)\n",
    "    return E/nrms[:,np.newaxis]\n",
    "\n",
    "def cosineSimilarity(E,v):\n",
    "    E = normalize(E)\n",
    "    v = normalize(v)\n",
    "    scores = E.dot(v.T)\n",
    "    return scores\n",
    "\n",
    "def getMostSimilarWords(E,word,W2I,topn=10):\n",
    "    if type(word) is str:\n",
    "        v = E[W2I[word],:]\n",
    "    else:\n",
    "        v = word\n",
    "    scores = cosineSimilarity(E,v)\n",
    "    scores = scores.squeeze()\n",
    "    sortedScores = np.sort(scores)[::-1]\n",
    "    idx = np.argsort(scores)[::-1]\n",
    "    topNScores = sortedScores[:topn]\n",
    "    topNWordsIdx = idx[:topn]\n",
    "    return topNScores,topNWordsIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'machine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27568/1236617682.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetMostSimilarWords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM_reduced\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'machine'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW2I\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mI2W\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27568/936141172.py\u001b[0m in \u001b[0;36mgetMostSimilarWords\u001b[1;34m(E, word, W2I, topn)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetMostSimilarWords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW2I\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mW2I\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'machine'"
     ]
    }
   ],
   "source": [
    "scores,idx = getMostSimilarWords(M_reduced,'machine',W2I)\n",
    "for i in range(len(idx)):\n",
    "    print(scores[i],I2W[idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.72737092 3.54336143 3.19724049]\n"
     ]
    }
   ],
   "source": [
    "print(getNorms(M_reduced[[1,4,5],:]))\n",
    "v.shape\n",
    "\n",
    "import dill\n",
    "def saveModel(model,fileNameDotpkl):\n",
    "    with open(fileNameDotpkl,'wb') as f:\n",
    "        dill.dump(model,f)\n",
    "\n",
    "model = M_reduced,W2I,I2W,vocab;\n",
    "saveModel(model,'../data/w2v_100d.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
